Rlist = c("RR1_500r6810","RR501_1000r6217","RR1001_1500r4830","RR1501_2000r4928")
#Rlist = c("RR1_500r6810","RR501_1000r6217")
for (k in 1:length(Rlist)) {
print(paste0(">> reading file - ",Rlist[k],".csv..."))
RRk = fread(paste0(Rlist[k],".csv"), encoding="UTF-8" )
if (k==1) { RR = RRk }   else { RR = rbind(RR,RRk) }
}
Rlist = c("RR1_500r6810","RR501_1000r6217","RR1001_1500r7707","RR1501_2000r8262")
#Rlist = c("RR1_500r6810","RR501_1000r6217")
for (k in 1:length(Rlist)) {
print(paste0(">> reading file - ",Rlist[k],".csv..."))
RRk = fread(paste0(Rlist[k],".csv"), encoding="UTF-8" )
if (k==1) { RR = RRk }   else { RR = rbind(RR,RRk) }
}
dim(RR);   head(RR,2)       #-- 28996 / 464636
Install.packages("swirl")
packageVersion("swirl")
Library(swirl)
Install_from_swirl("R Programming")
Swirl()
install.packages("swirl")
library(swirl)
install_from_swirl("R Programming")
swirl()
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data2/")
dim(RR);   head(RR,2)       #-- 28996 / 464636
##==*(1C) 啟動jieba分詞引擎 (worker())
library("jiebaR")     #-- 先安裝一次 jiebaR: install.packages("jiebaR)
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
########## (2) 斷詞 ##########
RR$title[1]   #-- [1] "自己的腰痠背痛自己救" --> 第一個討論主題
##==*(2A) 結巴分詞的三種調用方法 (wkr1,segment())
##== (方法1) worker引擎(一種數據結構)直接分詞：
wkr1[ RR$title[1] ]            #-- [1] "自己"     "的"       "腰痠背痛" "自己"     "救"
##==*(1C) 啟動jieba分詞引擎 (worker())
install.packages("jiebaR);
library("jiebaR")
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
########## (2) 斷詞 ##########
RR$title[1]   #-- [1] "自己的腰痠背痛自己救" --> 第一個討論主題
##==*(2A) 結巴分詞的三種調用方法 (wkr1,segment())
##== (方法1) worker引擎(一種數據結構)直接分詞：
wkr1[ RR$title[1] ]            #-- [1] "自己"     "的"       "腰痠背痛" "自己"     "救"
##== (方法2) 詞語導向worker引擎分詞：
wkr1 <= RR$title[1]            #-- [1] "自己"     "的"       "腰痠背痛" "自己"     "救"
##== (方法3) 用segment()函數調用worker()解析詞語：
segment( RR$title[1], wkr1 )   #-- [1] "自己"     "的"       "腰痠背痛" "自己"     "救"
##== (2B) worker的數據結構 (wkr1)
wkr1
# Worker Type:  Jieba Segment
#   Default Method  :  mix
#   Detect Encoding :  TRUE
#   Default Encoding:  UTF-8
#   Keep Symbols    :  FALSE
#   Output Path     :
#     Write File      :  TRUE
#   By Lines        :  FALSE
#   Max Word Length :  20
#   Max Read Lines  :  1e+05
# Fixed Model Components:
#   $dict  #-- [1] "C:\\Users\\Mike\\AppData\\Local\\Temp\\Rtmpy8ayO9/jiebaR_dict/dict/jieba.dict.utf8"
#   $user  #-- [1] "C:/Users/Mike/Documents/R/win-library/4.0/jiebaRD/dict/user.dict.utf8"
#   $hmm   #-- [1] "C:\\Users\\Mike\\AppData\\Local\\Temp\\Rtmpy8ayO9/jiebaR_dict/dict/hmm_model.utf8"
#   $stop_word   #-- NULL
#   $user_weight #-- [1] "max"
#   $timestamp   #-- [1] 1600239055
#   $default $detect $encoding $symbol $output $write $lines $bylines can be reset.
##== (2C) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
##== 只就 RR$title 關鍵字太少，難以分類，所以要用 RR$text
RRtitle = unique(RR$title);   length(RRtitle)   #-- (1) 共有1993個討論主題
content = NULL;   Ncontent = NULL
for (title in RRtitle) {                                   #-- (2) 同一討論主題的回文內容(RR$text),以"\n\n"串接
content = c(content, paste(title, paste(RR$text[which(RR$title==title)],collapse="\n\n"),collapse="\n\n"))
Ncontent = c(Ncontent, length(which(RR$title==title)))   #-- (3) length(which(條件)): 表示滿足條件的個數
}
length(content);   head(content,2)     #-- [1] 1993             #-- (4) content:討論主題的回文內容(RR$text)集合,
# [1] "自己的腰痠背痛自己救 板上偶爾有人在討論背痛或是腰痛問題\r\n然而上班族會腰痠背痛的原因不外乎：坐姿不正確 (我就是)、搬重物\r\n姊爬文看了一下，腰酸背痛的主因是肌肉緊繃，可透過『肌肉伸展』改善下背疼痛症狀。\r\n肌肉伸展最重要的部分是：核心肌群 和 大腿後肌群。\r\n講這麼多，還是來看教學影片最實在，感謝姊夫和翻譯者呀!只能幫分享回報了\n\n\n\nvivavida7749 wrote:\r\n板上偶爾有人在討論背...(恕刪)\n\r\n感覺是貼錯了⋯⋯應該是下背痛那幾篇...Jeff和譯者都佛心來著\r\nhttps://youtu.be/Z3-mYrVjBEo\r\nhttps://youtu.be/gYsXOKAfxTs\r\nhttps://youtu.be/vw-LIovZ_Os\r\nhttps://youtu.be/oXj3O0quR0E"
# [2] "德國坦克Dirk Nowitzki - 我可以得分，我可以創... 不管你是不是小牛迷\r\n不管你支持哪一隊\r\n不管今年總冠軍你看好哪邊...\r\n請靜下心來好好欣賞\r\n以下這篇文章是我看過最好的NBA文章之一\r\n很多人認為結果很重要\r\n但是對我來說\r\n不管最後結果如何\r\nDirk Nowitzki都是讓我最敬佩的偉大球星\r\n此文轉自巴哈姆特-NBA版德國坦克Dirk Nowitzki - 我可以得分，我可以創造屬於我的未來\n\n\n\nkevin0921185 wrote:\r\n不管你是不是小牛迷不...(恕刪)\n\r\nDirk 不錯，以前nash在的時候二個人的搭配我就覺得超強了，可惜小牛在中鋒這個位置上一直都補不到樣的人材，直到今年拳王加盟才算補到一個正經的，可惜今年又遇到熱火dirk的運氣太差了\n\n\n\nkevin0921185 wrote:\r\n不管你是不是小牛迷不...(恕刪)\n\r\n我看完 差點要哭了,\r\n感動...\n\n他平常得分能力跳投穩定度無話可說,但是在強大防守壓力下往往無法突圍\r\n所以要說他fade away無解? karl malone不用後仰就無解了~要不是遇到jordan\r\n~\"\"~\n\n\n\r\n太感人了\r\n德佬~加油呀!!!\r\n我相信今年一定會拿下總冠軍的!!\r\n跟了十年的小牛迷~我們要的就是總冠軍!!!!!\n\n\n\nkenyeh99 wrote:\r\n遇到熱火dirk的運氣太差\n\r\n還好啦\r\n他遇到打擺子的lakers自爆\r\n本來我想說玫瑰能攔胡一下LCD\r\n拳怕少壯嘛\n\n\n\n大紅荳 wrote:\r\n他平常得分能力跳投穩...(恕刪)\n\r\n馬龍投籃也是伸腳後仰...\r\n回正題\r\n巴哈那篇文章真的好看\r\n是我看過NBA文章第二讚的\r\n(看過最好的是當初國王對湖人前有人分析國王五虎的歷史)\r\n我支持過國王、馬刺\r\n小牛一直以來都是最大的勁敵\r\n原來我最欣賞的球員，就是過去最痛恨的敵人啊\r\n德佬加油!!\n\n很希望小牛可以如願，但是.....\r\n熱火今年太強了!\r\n只靠Dirk是不夠的!\r\nkidd、peja也要加油才行，\r\n還有，我對小牛總教練有點... <truncated>
Ncontent[1:10]   #-- [1] 2  34  20  49  11 125  20  18  20  4   #-- (5) Ncontent: 每個討論主題的回文數
########## (3) 詞性標註 (詞語標籤) ##########
##== (3A) 分詞引擎產生詞性(詞語標籤) (worker(type="tag"): content-->Dword0)
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag")
##== (2) 以隱式迴圈指令 sapply()，對向量content的各個元素，分別操作 wkr2() (content-->Dword0)
Dword0 = sapply(content, function(x) segment(tolower(as.character(x)), wkr2));   #-- 要先轉成文字型式(as.character)，並將其中的所有英文字轉為小寫(tolower)
##== (3) 切出的詞語 (第一個元素為Dword0[[1]]) 中 附有標籤
length(Dword0);   head(Dword0[[1]],10)   #-- [1] 1993   #-- 所得到的 Dword0 為由 content各個元素斷詞的表列(list)，共1993個表列元素
#     r         uj          n          r          v          x          d          r          p          v
# "自己"       "的" "腰痠背痛"     "自己"       "救"     "板上"     "偶爾"     "有人"       "在"     "討論"
##== (3B) 以正規表示法提取特定詞性 (Dword0-->Dword)
##== (1) 正規表示式(RegExp, Regular Expression): POSIX 1003.2國際標準 [Stephen Kleene, 1956]
#    -- (a)匹配: 句點(任何字元),方括號(其中任何字元),
#    -- (b)重覆: ?(一次),*(0次以上),+(1次以上)
#    -- (c)位置: ^(字串開始), $(字串結束)
wordset = c("鄭州市","蓮花街","中原區","思明區","李大爺","張三豐","李四")
nKind = NULL
nKind[grep("*市$",wordset)] = "nCity"
nKind[grep("*區$",wordset)] = "nArea"
nKind[grep("^李+",wordset)] = "nPerson"
nKind
nKind[grep("[李,張]+",wordset)] = "nPerson"
nKind
##== (2) 過濾掉 單字詞 與 數字帶頭的詞語 (Dword0-->Dword)
Dword = lapply(Dword0, function(x){
nx=sapply(x,nchar); xA=x[nx>=2]; #-- 過濾掉 單字詞，取出字長大於2的詞語 nchar(x)>=2
return( xA[-grep("[[:digit:]]+",xA)] )
} );   #-- 過濾掉 數字帶頭的詞語 [[:digit:]]+
length(Dword);   head(Dword[[1]],10)  #-- [1] 1993
#     r          n          r          x          d          r          v          n          c          n
# "自己" "腰痠背痛"     "自己"     "板上"     "偶爾"     "有人"     "討論"     "背痛"     "或是"     "腰痛"...
#  代詞       名詞       代詞     字符串       副詞       代詞       動詞       名詞       連詞       名詞 ...
##== (3C) 詞語標籤(tag: names(Dword))
##== 詞語標籤(tag)的定義: ICTPOS3.0词性标记集
#    -- ICTCLAS（Institute of Computing Technology, Chinese Lexical Analysis System）
#    --   中國科學院計算技術研究所 的 漢語詞法分析系統，以多層HMM(隱馬克夫模型)研發
#    --   主要功能包括中文分詞；詞性標註；命名實體識別；新詞識別，與用戶詞典
#     	n 名词
#                nr 人名
#                       nr1 汉语姓氏
#                       nr2 汉语名字
#                       nrj 日语人名
#                       nrf 音译人名
#                ns 地名
#                       nsf 音译地名
#                nt 机构团体名
#                nz 其它专名
#                nl 名词性惯用语
#                ng 名词性语素
#        t 时间词
#                tg 时间词性语素
# ...
##== (3D) 語言學的語詞分類 [C.C.Fries, 1952]
##== (1) 功能詞(function words)
#        -- Words that have little lexical meaning or have ambiguous meaning
#        -- express grammatical relationships with other words within a sentence, or specify the attitude or mood of the speaker.
#        -- might be prepositions, pronouns, auxiliary verbs, conjunctions, grammatical articles or particles
##== (2) 內容詞(content words or lexical words)
#        -- Words that are not function words
#        -- Dictionaries: define the specific meanings of content words, but can only describe the general usages of function words.
#        -- include <實體詞> nouns(名詞), verbs(動詞), <修飾詞> adjectives, and most adverbs, although some adverbs are function words (e.g., then, and, why)
Dword = lapply(Dword0, function(x){ nx=sapply(x,nchar); xA=x[nx>=2];
return( xA[substr(names(xA),1,1) %in% c("n","v")] ) } );   Dword[[1]]  #-- grep() 似乎有出入,改用substr()
#         n          v          n          n          n         nz          n          n          n          n          n          n          n
# "腰痠背痛"     "討論"     "背痛"     "腰痛"     "問題"   "上班族" "腰痠背痛"     "原因"     "坐姿"     "重物" "腰酸背痛"     "主因"     "肌肉"
#     v          n          v          v          n          n          n          v          n          n          n          n          n
# "透過"     "肌肉"     "伸展"     "改善"     "疼痛"     "症狀"     "肌肉"     "伸展"     "部分"     "核心"     "大腿"     "教學"     "影片"
#     v          v          n          n          v          v          v          v          n          v          n          n          n
# "實在"     "感謝"     "姊夫"   "翻譯者"     "只能"     "分享"     "回報"     "討論"     "感覺"     "應該"     "背痛"     "譯者"     "佛心"
##== (3E) 詞庫
show_dictpath()       ##== (1) 預設詞庫目錄  #-- [1] "C:/Users/Mike/Documents/R/win-library/4.0/jiebaRD/dict"
dir(show_dictpath())  ##== (2) 目錄中詞庫
# [1] "backup.rda"      "hmm_model.zip"   "idf.zip"         "jieba.dict.zip"  "model.rda"       "README.md"
# [7] "stop_words.utf8" "user.dict.utf8"
##== (3) 預設詞庫
scan(file="C:/Users/Mike/Documents/R/win-library/4.0/jiebaRD/dict/jieba.dict/jieba.dict.utf8",
what=character(), nlines=30, sep='\n', encoding='utf-8', fileEncoding='utf-8')   #-- 詞項 詞頻 詞性標記
#--> 因權限打不開, 可以直接開
# [1] "1号店 3 n"  "1號店 3 n"  "4S店 3 n"   "4s店 3 n"   "AA制 3 n"   "AB型 3 n"   "AT&T 3 nz"  "A型 3 n"    "A座 3 n"    "A股 3 n"
# [11] "A輪 3 n"    "A轮 3 n"    "BB机 3 n"   "BB機 3 n"   "BP机 3 n"   "BP機 3 n"   "B型 3 n"    "B座 3 n"    "B股 3 n"    "B超 3 n"
# [21] "B輪 3 n"    "B轮 3 n"    "C# 3 nz"    "C++ 3 nz"   "CALL机 3 n" "CALL機 3 n" "CD机 3 n"   "CD機 3 n"   "CD盒 3 n"   "C座 3 n"
##==*(1C) 啟動jieba分詞引擎 (worker())
install.packages("jiebaR)
library("jiebaR")     #-- 先安裝一次 jiebaR: install.packages("jiebaR)
##==*(1C) 啟動jieba分詞引擎 (worker())
install.packages("jiebaR")
install.packages("jiebaR")
library("jiebaR")     #-- 先安裝一次 jiebaR: install.packages("jiebaR)
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
########## (2) 斷詞 ##########
RR$title[1]   #-- [1] "自己的腰痠背痛自己救" --> 第一個討論主題
RR$title[1]   #-- [1] "自己的腰痠背痛自己救" --> 第一個討論主題
##==*(2A) 結巴分詞的三種調用方法 (wkr1,segment())
##== (方法1) worker引擎(一種數據結構)直接分詞：
wkr1[ RR$title[1] ]            #-- [1] "自己"     "的"       "腰痠背痛" "自己"     "救"
##== (方法2) 詞語導向worker引擎分詞：
wkr1 <= RR$title[1]            #-- [1] "自己"     "的"       "腰痠背痛" "自己"     "救"
##== (2B) worker的數據結構 (wkr1)
wkr1
RR$title[1]   #-- [1] "自己的腰痠背痛自己救" --> 第一個討論主題
##== (2A) 結巴分詞的三種調用方法 (wkr1,segment())
wkr1[ RR$title[1] ]    ##== (方法1) worker引擎(一種數據結構)直接分詞：
wkr1 <= RR$title[1]    ##== (方法2) 詞語導向worker引擎分詞：
segment( RR$title[1], wkr1 )   ##== (方法3) 用segment()函數調用worker()解析詞語：
##== (2B) worker的數據結構 (wkr1)
wkr1
##== (2C) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
##== 只就 RR$title 關鍵字太少，難以分類，所以要用 RR$text
RRtitle = unique(RR$title);   length(RRtitle)   #-- (1) 共有1993個討論主題
content = NULL;   Ncontent = NULL
for (title in RRtitle) {                                   #-- (2) 同一討論主題的回文內容(RR$text),以"\n\n"串接
content = c(content, paste(title, paste(RR$text[which(RR$title==title)],collapse="\n\n"),collapse="\n\n"))
Ncontent = c(Ncontent, length(which(RR$title==title)))   #-- (3) length(which(條件)): 表示滿足條件的個數
}
length(content);   head(content,2)     #-- [1] 1993             #-- (4) content:討論主題的回文內容(RR$text)集合,
##== (2C) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
##== 只就 RR$title 關鍵字太少，難以分類，所以要用 RR$text
RRtitle = unique(RR$title);
length(RRtitle)   #-- (1) 共有1993個討論主題
content = NULL;   Ncontent = NULL
for (title in RRtitle) {                                   #-- (2) 同一討論主題的回文內容(RR$text),以"\n\n"串接
content = c(content, paste(title, paste(RR$text[which(RR$title==title)],collapse="\n\n"),collapse="\n\n"))
Ncontent = c(Ncontent, length(which(RR$title==title)))   #-- (3) length(which(條件)): 表示滿足條件的個數
}
##== (2C) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
##== 只就 RR$title 關鍵字太少，難以分類，所以要用 RR$text
RRtitle = unique(RR$title);
length(RRtitle)    #-- 有1993個討論主題
content = NULL
Ncontent = NULL
#-- 同一討論主題的回文內容(RR$text),以"\n\n"串接，length(which(條件)): 表示滿足條件的個數
for (title in RRtitle) {
content = c(content, paste(title, paste(RR$text[which(RR$title==title)],collapse="\n\n"),collapse="\n\n"))
Ncontent = c(Ncontent, length(which(RR$title==title)))
}
head(content,2)
length(content)     #-- 1993
wkr2 = worker(type="tag")
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag")
##== (2) 以隱式迴圈指令 sapply()，對向量content的各個元素，分別操作 wkr2() (content-->Dword0)
Dword0 = sapply(content, function(x) segment(tolower(as.character(x)), wkr2));   #-- 要先轉成文字型式(as.character)，並將其中的所有英文字轉為小寫(tolower)
##== (3) 切出的詞語 (第一個元素為Dword0[[1]]) 中 附有標籤
length(Dword0);   head(Dword0[[1]],10)   #-- [1] 1993   #-- 所得到的 Dword0 為由 content各個元素斷詞的表列(list)，共1993個表列元素
#    -- (a)匹配: 句點(任何字元),方括號(其中任何字元),
#    -- (b)重覆: ?(一次),*(0次以上),+(1次以上)
#    -- (c)位置: ^(字串開始), $(字串結束)
wordset = c("鄭州市","蓮花街","中原區","思明區","李大爺","張三豐","李四")
head(Dword0[[1]],10)   #-- [1] 1993   #-- 所得到的 Dword0 為由 content各個元素斷詞的表列(list)，共1993個表列元素
##== (3) 切出的詞語 (第一個元素為Dword0[[1]]) 中 附有標籤
length(Dword0);
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag")
##== (2) 以隱式迴圈指令 sapply()，對向量content的各個元素，分別操作 wkr2() (content-->Dword0)
Dword0 = sapply(content, function(x) segment(tolower(as.character(x)), wkr2));   #-- 要先轉成文字型式(as.character)，並將其中的所有英文字轉為小寫(tolower)
##== (3) 切出的詞語 (第一個元素為Dword0[[1]]) 中 附有標籤
length(Dword0);
head(Dword0[[1]],10)   #-- [1] 1993   #-- 所得到的 Dword0 為由 content各個元素斷詞的表列(list)，共1993個表列元素
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag")
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag"); wrk2
##== (1A) (KDD1) 讀取數據 (RRlist/RR....csv-->RR)
library(data.table)
Rlist = c("RR1_500r6810","RR501_1000r6217","RR1001_1500r7707","RR1501_2000r8262")
for (k in 1:length(Rlist)) {
print(paste0(">> reading file - ",Rlist[k],".csv..."))
RRk = fread(paste0(Rlist[k],".csv"), encoding="UTF-8" )
if (k==1) { RR = RRk }   else { RR = rbind(RR,RRk) }
}
dim(RR);   head(RR,2)       #-- 28996 / 464636
install.packages("jiebaR")
install.packages("jiebaR")
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
#install.packages("jiebaR")
library("jiebaR")
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
RR$title[1]   #-- [1] "自己的腰痠背痛自己救" --> 第一個討論主題
##== (2A) 結巴分詞的三種調用方法 (wkr1,segment())
wkr1[ RR$title[1] ]    ##== (方法1) worker引擎(一種數據結構)直接分詞：
##== (1A) (KDD1) 讀取數據 (RRlist/RR....csv-->RR)
library(data.table)
#Rlist = c("RR1_500r6810","RR501_1000r6217","RR1001_1500r7707","RR1501_2000r8262")
Rlist = c("RR1_500r6810")
for (k in 1:length(Rlist)) {
print(paste0(">> reading file - ",Rlist[k],".csv..."))
RRk = fread(paste0(Rlist[k],".csv"), encoding="UTF-8" )
if (k==1) { RR = RRk }   else { RR = rbind(RR,RRk) }
}
dim(RR);
head(RR,2)       #-- 28996 / 464636
#install.packages("jiebaR")
library("jiebaR")
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
RR$title[1]   #-- [1] "自己的腰痠背痛自己救" --> 第一個討論主題
##== (2A) 結巴分詞的三種調用方法 (wkr1,segment())
wkr1[ RR$title[1] ]    ##== (方法1) worker引擎(一種數據結構)直接分詞：
##== (2B) worker的數據結構 (wkr1)
wkr1
##== (4) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
RRtitle = unique(RR$title);    ##==
RRtitle
##== (4) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
RRtitle = unique(RR$title)     ##== List all  $title
RRtitle
length(RRtitle)     #-- 1993個討論主題
content = NULL
Ncontent = NULL
#-- 同一討論主題的回文內容(RR$text),以"\n\n"串接，length(which(條件)): 表示滿足條件的個數
for (title in RRtitle) {
content = c(content, paste(title, paste(RR$text[which(RR$title==title)],collapse="\n\n"),collapse="\n\n"))
Ncontent = c(Ncontent, length(which(RR$title==title)))
}
head(content,2)
head(content,2)     #== 把 RRtitle(content) 資料列出， 輸出\r\n 表換行，輸出 \n\n\n\n 下一筆資料
length(content)     #-- 1993
Ncontent[1:10]   #-- [1] 2  34  20  49  11 125  20  18  20  4   #-- (5) Ncontent: 每個討論主題的回文數
length(content)     #-- 1993
Ncontent[1:10]   #-- [1] 2  34  20  49  11 125  20  18  20  4   #-- (5) Ncontent: 每個討論主題的回文數
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag"); wrk2
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag");
wrk2
wkr1
##== (1) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性
wkr2 = worker(type="tag")
wkr2
##== (2) 以隱式迴圈指令 sapply()，對向量content的各個元素，分別操作 wkr2() (content-->Dword0)
Dword0 = sapply(content, function(x) segment(tolower(as.character(x)), wkr2));   #-- 要先轉成文字型式(as.character)，並將其中的所有英文字轉為小寫(tolower)
##== (3) 切出的詞語 (第一個元素為Dword0[[1]]) 中 附有標籤
length(Dword0);
head(Dword0[[1]],10)   #-- [1] 1993   #-- 所得到的 Dword0 為由 content各個元素斷詞的表列(list)，共1993個表列元素
Dword0
##== (3) 切出的詞語 (第一個元素為Dword0[[1]]) 中 附有標籤
length(Dword0);
length(Dword0);        #-- 500
head(Dword0[[1]],10)   #-- [1] 1993   #-- 所得到的 Dword0 為由 content各個元素斷詞的表列(list)，共1993個表列元素
head(Dword0[[1]],3)   #-- $title 標題資料第一筆
head(Dword0[[1]],5)   #-- $title 標題資料第一筆
head(Dword0[[2]],5)    #-- $title 標題資料第一筆，sapply 自動切分出各個元素
head(Dword0[[1]],5)    #-- $title 標題資料第一筆，sapply 自動切分出各個元素
##== (3) 以正規表示法提取特定詞性 (Dword0-->Dword)
wordset = c("鄭州市","蓮花街","中原區","思明區","李大爺","張三豐","李四")
nKind = NULL
nKind[grep("*市$",wordset)] = "nCity"
nKind[grep("*區$",wordset)] = "nArea"
nKind[grep("^李+",wordset)] = "nPerson"
nKind
##== (3) 以正規表示法提取特定詞性 (Dword0-->Dword)
wordset = c("鄭州市","蓮花街","中原區","思明區","李大爺","張三豐","李四")
nKind = NULL
nKind[grep("*市$",wordset)] = "nCity"
nKind[grep("*區$",wordset)] = "nArea"
########## (2) 詞性標註  ##########
wordset = c("鄭州市","蓮花街","中原區","思明區","李大爺","張三豐","李四")
nKind = NULL
nKind[grep("*市$",wordset)] = "nCity"
nKind[grep("*區$",wordset)] = "nArea"
nKind[grep("^李+",wordset)] = "nPerson"
nKind
nKind
nKind[grep("[李,張]+",wordset)] = "nPerson"
nKind
##== (2) 過濾掉 單字詞 與 數字帶頭的詞語 (Dword0-->Dword)
Dword = lapply(Dword0, function(x){
nx=sapply(x,nchar); xA=x[nx>=2]; #-- 過濾掉 單字詞，取出字長大於2的詞語 nchar(x)>=2
return( xA[-grep("[[:digit:]]+",xA)] )
} );   #-- 過濾掉 數字帶頭的詞語 [[:digit:]]+
Dword0 = sapply(content, function(x) segment(tolower(as.character(x)), wkr2));   #-- 要先轉成文字型式(as.character)，並將其中的所有英文字轉為小寫(tolower)
length(Dword0);        #-- 500
head(Dword0[[1]],5)    #-- $title 標題資料第一筆，sapply 自動切分出各個元素
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data2/")
install.packages( c("data.table","jiebaR","stringr","text2vec","wordcloud") )
#Rlist = c("RR1_500r6810","RR501_1000r6217","RR1001_1500r7707","RR1501_2000r8262")
Rlist = c("RR1_500r6810")
for (k in 1:length(Rlist)) {
print(paste0(">> reading file - ",Rlist[k],".csv..."))
RRk = fread(paste0(Rlist[k],".csv"), encoding="UTF-8" )
if (k==1) { RR = RRk }   else { RR = rbind(RR,RRk) }
}
install.packages(c("data.table", "jiebaR", "stringr", "text2vec", "wordcloud"))
dim(RR);         #-- 6810   12
head(RR,2)       #-- 28996 / 464636
##== (2) 中文文本分析工具jieba
install.packages("jiebaR")
library("jiebaR")
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
RR$title[1]         #-- title 標題 第1筆資料
##== (3) 結巴分詞的三種調用方法 (wkr1,segment())
wkr1[ RR$title[1] ]            ##== (方法1) worker引擎(一種數據結構)直接分詞：
wkr1 <= RR$title[1]            ##== (方法2) 詞語導向worker引擎分詞：
segment( RR$title[1], wkr1 )   ##== (方法3) 用segment()函數調用worker()解析詞語：
wkr1
##== (4) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
RRtitle = unique(RR$title)     ##== List all  $title
RRtitle
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data2/")
##== (1) (KDD1) 讀取數據 (RRlist/RR....csv-->RR)
library(data.table)
Rlist = c("RR1_500r6810")   #Rlist = c("RR1_500r6810","RR501_1000r6217","RR1001_1500r7707","RR1501_2000r8262")
for (k in 1:length(Rlist)) {
print(paste0(">> reading file - ",Rlist[k],".csv..."))
RRk = fread(paste0(Rlist[k],".csv"), encoding="UTF-8" )
if (k==1) { RR = RRk }   else { RR = rbind(RR,RRk) }
}
dim(RR);         #-- 6810   12
head(RR,2)       #-- 28996 / 464636
##== (2) 中文文本分析工具jieba
install.packages("jiebaR")
install.packages("jiebaR")
##== (2) 中文文本分析工具jieba
#install.packages("jiebaR")
library("jiebaR")
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
RR$title[1]         #-- title 標題 第1筆資料
##== (3) 結巴分詞的三種調用方法 (wkr1,segment())
wkr1[ RR$title[1] ]            ##== (方法1) worker引擎(一種數據結構)直接分詞：
wkr1 <= RR$title[1]            ##== (方法2) 詞語導向worker引擎分詞：
segment( RR$title[1], wkr1 )   ##== (方法3) 用segment()函數調用worker()解析詞語：
#wkr1 <= RR$title[1]            ##== (方法2) 詞語導向worker引擎分詞：
#segment( RR$title[1], wkr1 )   ##== (方法3) 用segment()函數調用worker()解析詞語：
wkr1
##== (3) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
RRtitle = unique(RR$title)     ##== List all  $title
RRtitle
RRtitle
length(RRtitle)                ##== $title 有 500個
content = NULL
Ncontent = NULL
for (title in RRtitle) {
content = c(content, paste(title, paste(RR$text[which(RR$title==title)],collapse="\n\n"),collapse="\n\n"))
Ncontent = c(Ncontent, length(which(RR$title==title)))
}
head(content,2)     #== 把 RRtitle(content) 資料列出2筆， 輸出：\r\n 換行，\n\n\n\n 下一筆資料
length(content)
##== (4) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性，以 sapply()，對向量content的各個元素，分別操作 wkr2() (content-->Dword0)
wkr2 = worker(type="tag")
wkr2
wkr1[ RR$title[1] ]; wkr1             ##== (方法1) jiebaR 調用，worker引擎(一種數據結構)直接分詞：
##== (4) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性，以 sapply()，對向量content的各個元素，分別操作 wkr2() (content-->Dword0)
wkr2 = worker(type="tag"); wkr2
Dword0 = sapply(content, function(x) segment(tolower(as.character(x)), wkr2));   #-- 要先轉成文字型式(as.character)，並將其中的所有英文字轉為小寫(tolower)
length(Dword0);        #-- 500
head(Dword0[[1]],5)    #-- $title 標題資料第一筆，sapply 自動切分出各個元素
##== (2) 過濾掉 單字詞 與 數字帶頭的詞語 (Dword0-->Dword)
Dword = lapply(Dword0, function(x){
nx=sapply(x,nchar); xA=x[nx>=2]; #-- 過濾掉 單字詞，取出字長大於2的詞語 nchar(x)>=2
return( xA[-grep("[[:digit:]]+",xA)] )
} );   #-- 過濾掉 數字帶頭的詞語 [[:digit:]]+
length(Dword);   head(Dword[[1]],10)  #-- [1] 1993
##== (5) 過濾掉 單字詞 與 數字帶頭的詞語 (Dword0-->Dword)
Dword = lapply(Dword0, function(x){
nx=sapply(x,nchar); xA=x[nx>=2]; #-- 過濾掉 單字詞，取出字長大於2的詞語 nchar(x)>=2
return( xA[-grep("[[:digit:]]+",xA)] )
} );   #-- 過濾掉 數字帶頭的詞語 [[:digit:]]+
length(Dword);
head(Dword[[1]],10)  #-- [1] 1993
Dword = lapply(Dword0, function(x){
nx=sapply(x,nchar); xA=x[nx>=2];
return( xA[-grep("[[:digit:]]+",xA)] )
} )
length(Dword);
head(Dword[[1]],10)  #-- [1] 1993
head(Dword[[1]],4)  #-- [1] 1993  #
head(Dword[[1]],3)  #-- [1] 1993  #
Dword = lapply(Dword0, function(x){ nx=sapply(x,nchar); xA=x[nx>=2];
return( xA[substr(names(xA),1,1) %in% c("n","v")] ) } );   Dword[[1]]  #-- grep() 似乎有出入,改用substr()
Dword = lapply(Dword0, function(x){ nx=sapply(x,nchar); xA=x[nx>=2];
return( xA[substr(names(xA),1,1) %in% c("n","v")] ) } );   Dword[[1]]  #-- grep() 似乎有出入,改用substr()
Dword = lapply(Dword0, function(x){ nx=sapply(x,nchar); xA=x[nx>=2]; return( xA[substr(names(xA),1,1) %in% c("n","v")] ) } );
Dword[[1]]  #-- grep() 似乎有出入,改用substr()
##== (3E) 詞庫
show_dictpath()       ##== (1) 預設詞庫目錄  #-- [1] "C:/Users/Mike/Documents/R/win-library/4.0/jiebaRD/dict"
dir(show_dictpath())  ##== (2) 目錄中詞庫
?jabei
?jiebaR
wordset = c("鄭州市","蓮花街","中原區","思明區","李大爺","張三豐","李四")  #設定一個字串
nKind = NULL
nKind[grep("*市$",wordset)] = "nCity"    #取所有 市$ 標籤 nCity
nKind[grep("*區$",wordset)] = "nArea"    #取所有 區$ 標籤 nArea
nKind[grep("^李+",wordset)] = "nPerson"  #取所有 李+ 開頭，標籤 nPerson
nKind[grep("[李,張]+",wordset)] = "nPerson"
nKind
##== (1) (KDD1) 讀取數據 (RRlist/RR....csv-->RR)
library(data.table)
Rlist = c("RR1_500r6810")                                   #Rlist = c("RR1_500r6810","RR501_1000r6217","RR1001_1500r7707","RR1501_2000r8262")
for (k in 1:length(Rlist)) {
print(paste0(">> reading file - ",Rlist[k],".csv..."))
RRk = fread(paste0(Rlist[k],".csv"), encoding="UTF-8" )
if (k==1) { RR = RRk }   else { RR = rbind(RR,RRk) }
}
dim(RR);         #-- 6810   12
head(RR,2)       #-- 28996 / 464636
##== (2) 中文文本分析工具jieba
#install.packages("jiebaR")
library("jiebaR")
wkr1 = worker()     #-- 最基本的 jieba 分詞引擎
RR$title[1]         #-- title 標題 第1筆資料
wkr1[ RR$title[1] ]; wkr1             ##== (方法1) jiebaR 調用，worker引擎(一種數據結構)直接分詞：
##== (3) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
RRtitle = unique(RR$title)     ##== 列出全部 $title
#wkr1[ RR$title[1] ]; wkr1             ##== (方法1) jiebaR 調用，worker引擎(一種數據結構)直接分詞：
wkr1 = RR$title[1] ; wkr1            ##== (方法2) jiebaR 調用，詞語導向worker引擎分詞：
wkr1[ RR$title[1] ]; wkr1             ##== (方法1) jiebaR 調用，worker引擎(一種數據結構)直接分詞：
##== (3) (KDD3) 實務數據的斷詞 (RR$title/RR$text-->content/Ncontent)
RRtitle = unique(RR$title)     ##== 列出全部 $title
RRtitle
length(RRtitle)                ##== $title 有 500個
content = NULL
Ncontent = NULL
for (title in RRtitle) {
content = c(content, paste(title, paste(RR$text[which(RR$title==title)],collapse="\n\n"),collapse="\n\n"))
Ncontent = c(Ncontent, length(which(RR$title==title)))
}
head(content,2)     #== 把 RRtitle(content) 資料列出2筆， 輸出：\r\n 換行，\n\n\n\n 下一筆資料
##== (4) 在工作引擎中加上"tag"參數，使分詞時同時產生詞性，以 sapply()，對向量content的各個元素
wkr2 = worker(type="tag"); wkr2
Dword0 = sapply(content, function(x) segment(tolower(as.character(x)), wkr2));   #-- 要先轉成文字型式(as.character)，並將其中的所有英文字轉為小寫(tolower)
length(Dword0);        #-- 500
head(Dword0[[1]],5)    #-- $title 標題資料第一筆，sapply 自動切分出各個元素
Dword = lapply(Dword0, function(x){
nx=sapply(x,nchar); xA=x[nx>=2];       #取出字>=2的詞語
return( xA[-grep("[[:digit:]]+",xA)] ) #過濾數字帶頭的詞語 [[:digit:]]+
} )
length(Dword);
head(Dword[[1]],3)  #-- 上方 lappy 僅保留字數 >=2 的值做回傳
Dword = lapply(Dword0, function(x){ nx=sapply(x,nchar); xA=x[nx>=2]; return( xA[substr(names(xA),1,1) %in% c("n","v")] ) } );
Dword[[1]]  #-- grep() 似乎有出入,改用substr()
source('~/Documents/Github/USC_R_Git/2.R-tech/data2/Rtech02.R', echo=TRUE)
wordset = c("鄭州市","蓮花街","中原區","思明區","李大爺","張三豐","李四")  #設定一個字串
nKind = NULL
nKind[grep("*市$",wordset)] = "nCity"    #取所有 市$ 標籤 nCity
