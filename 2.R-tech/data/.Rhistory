##==> 用迴圈包成Gfeature
Gfeature = NULL
for (k in 1:dim(Gmean)[1]) {
print(k)
AA = paste0(round(Gmean[k,3:5],2), " * ", colnames(Gmean)[3:5]);  AA
BB = paste( AA, collapse="+")
print(BB)
Gfeature[k] = BB
}
Gfeature
##==> 把Gmean,Gfeature合成數據框
Gm = as.data.frame(Gmean);  head(Gm)
colnames(Gm)[1:2] = c("ind","count");   head(Gm)
Gm$feature = Gfeature
head(Gm)
write.csv(Gm,"Team1.csv")
library(arules);library(igraph)
PD=table(X$Category,X$Year)
rownames(PD) = NULL;  #PD     # 1-33個品項  #PD[1:10,]
#以下計算只取PD值
txPD = lapply( 1:dim(PD)[1],
FUN=function(k) colnames(PD)[which(PD[k,]>0)] )
arPD = apriori( txPD[1:6],
parameter=list(support=0.06, confidence=0.8),
control=list(verbose=FALSE))
#lhs=>rhs 代表買左邊也會買右邊的意思，而支持度與信賴度，則分別代表了普遍性與信心水準。
inPD = inspect(arPD[9:20,])
#lhs=>rhs 代表買左邊也會買右邊的意思，而支持度與信賴度，則分別代表了普遍性與信心水準。
#inPD = inspect(arPD[9:20,])
graph.arPD = graph.edgelist( cbind(inspect(arPD)[1:50,]$lhs,
inspect(arPD)[1:50,]$rhs) )
library(arules);library(igraph)
PD=table(X$Category,X$Year)
rownames(PD) = NULL;  #PD     # 1-33個品項  #PD[1:10,]
txPD = lapply( 1:dim(PD)[1],
FUN=function(k) colnames(PD)[which(PD[k,]>0)] )
arPD = apriori( txPD[1:6],
parameter=list(support=0.06, confidence=0.8),
control=list(verbose=FALSE))
#@
# apriori演算法大概是這樣運作的，我們必須要設定support以及confidence:
pander(">> (1)我們採用 apriori 演算法\n\n");
pander(">> (2)支持度(support)：「規則」在資料內具有普遍性，也就是這些 A 跟 B 同時出現的機率多少\n\n");
pander(">> (3)信賴度(confidence)：「規則」要有一定的信心水準，也就是當購買 A 狀態下，也會購買 B 的條件機率\n\n")
kable(inspect(arPD[9:20,]))%>%
kable_styling(c("striped", "bordered")) %>%
kable_styling(full_width = F) %>%
column_spec(1, bold = T)
search()
arPD[3:31,]
#####===== (1) (KDD1) 讀取數據(-->X) =====#####
library(readxl)
X <- as.data.frame(read_excel('/Users/Eugina/Desktop/USC_code/data/googleplaystore4.xlsX'))
dim(X);
head(X,2)
#####===== (2) (KDD2-3) 數據轉換(X-->XX) =====#####
range(X$Rating)
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
#####===== (1) (KDD1) 讀取數據(-->X) =====#####
library(readxl)
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
dim(X);
head(X,2)
#####===== (2) (KDD2-3) 數據轉換(X-->XX) =====#####
range(X$Rating)
table( cut(X$Rating, breaks=c(0,1,2,3,4,5)) )
range(X$Year)   #2010 - 2018
table(X$Year)
XX = X[which(X$Year>=2018),];   dim(XX)
rownames(XX) = 1:dim(XX)[1] #設定row名稱
XX
#####===== (3) (KDD4) 數據模型(XX-->XX.group) =====#####
#算距離#ward d離差平方和
X.hc = hclust( dist( X[,c("Rating","Reviews","Installs")] ),method="ward.D"); X.hc #dist(,method=)認定distance的使用方法
head(X.hc,2)
#分群
X.group = cutree(X.hc, k=20);X.group
table(X.group)
Ncls = 20  #cause k =20
X[which(X.group==1),c("Rating","Reviews","Installs")]
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, max),0)
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, min),0)
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, mean),2)
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, sd),2)
X.group
#####===== (4) (KDD5) 數據解讀(XX.group) =====#####
kk = 1  #X.group(kk)
indKK = which(X.group==kk);   indKK
c(kk,length(indKK), apply(X[indKK,c("Rating","Reviews","Installs")], 2, mean))
##== Group Means (Gmean) ==##
Gmean = NULL
for (kk in 1:Ncls) {
indKK = which(X.group==kk);   indKK
c(kk,length(indKK), apply(X[indKK,c("Rating","Reviews","Installs")], 2, mean))
Gmean = rbind(Gmean, c(kk,length(indKK), apply(X[indKK,c("Rating","Reviews","Installs")], 2, mean)))
}
round(Gmean,2)[order(Gmean[,2],decreasing=T),][1:2,]
##== Group Features (Gfeature) ==##
colnames(Gmean)
round(Gmean[1,],2)
AA = paste0(round(Gmean[1,3:5],2), " * ", colnames(Gmean)[3:5]);  AA
BB = paste( AA, collapse=" + ");   BB
##==> 用迴圈包成Gfeature
Gfeature = NULL
for (k in 1:dim(Gmean)[1]) {
print(k)
AA = paste0(round(Gmean[k,3:5],2), " * ", colnames(Gmean)[3:5]);  AA
BB = paste( AA, collapse="+")
print(BB)
Gfeature[k] = BB
}
Gfeature
##==> 把Gmean,Gfeature合成數據框
Gm = as.data.frame(Gmean);  head(Gm)
colnames(Gm)[1:2] = c("ind","count");   head(Gm)
Gm$feature = Gfeature
head(Gm)
write.csv(Gm,"Team1.csv")
#--- Rtech04 ----
# install.packages( c("arules","arulesViz","igraph","data.table","jiebaR","text2vec") )
setwd("/Users/Eugina/Desktop/USC_code/data/")
library(arules);library(igraph)
#--- Rtech04 ----
# install.packages( c("arules","arulesViz","igraph","data.table","jiebaR","text2vec") )
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data")
library(arules);library(igraph)
#data(Groceries)
#X = read.csv("googleplaystore4.csv");   dim(X);   head(X,2)
# [1] 7684   16
# App                                            Category Rating   Reviews Size Installs Type Price Content.Rating                    Genres Last.Updated Year Month Day Current.Ver  Android.Ver
# Photo Editor & Candy Camera & Grid & ScrapBook ART_AND_DESIGN    4.1     159  19M    10,000 Free     0       Everyone              Art & Design     7-Jan-18 2018     1   7       1.0.0 4.0.3 and up
#                            Coloring book moana ART_AND_DESIGN    3.9     967  14M   500,000 Free     0       Everyone Art & Design;Pretend Play    15-Jan-18 2018     1  15       2.0.0 4.0.3 and up
summary(X)
#table(table(X$Category))
#table(table(X$Genres))[1:17]
# 37   38   43   47   51   56   59   61   63   84   89   95  110  116  144  160  166  171  177  179  211  223  235  245  247  266  278  279  324  627  966 1602
# 1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1
t(X[1:20,7:10]) #[橫：直]
# measure 評估各個品類(Category) 在有多少有 免費/年份推出
#PG=table(X$Category,X$Year);   rownames(PG)=NULL;  PG  # 1-33個品項  #PG[1:10,]
PD=table(X$Category,X$Year);   rownames(PD)=NULL;  PD     # 1-33個品項  #PD[1:10,]
# apriori演算法大概是這樣運作的，我們必須要設定support以及confidence:
# 支持度(support)：「規則」在資料內具有普遍性，也就是這些 A 跟 B 同時出現的機率多少。
# 信賴度(confidence)：「規則」要有一定的信心水準，也就是當購買 A 狀態下，也會購買 B 的條件機率。
FUN=function(k) colnames(PD)[which(PD[k,]>0)]
txPD = lapply( 1:dim(PD)[1], FUN=function(k) colnames(PD)[which(PD[k,]>0)] )
#取出有代表性資料
arPD = apriori( txPD[1:6], parameter=list(support=0.06, confidence=0.8), control=list(verbose=FALSE));
#lhs=>rhs 代表買左邊也會買右邊的意思，而支持度與信賴度，則分別代表了普遍性與信心水準。
inspect(arPD[9:20,]) #第9之前有空集合
graph.arPD = graph.edgelist( cbind(inspect(arPD)[1:50,]$lhs, inspect(arPD)[1:50,]$rhs) )
plot(graph.arPD, edge.arrow.size=0.1, edge.curved=0.3)
XX = X[,c("Price","Rating")]
cor(XX)   #-- correlation
XX.lm = lm(Price~Rating,data=XX);   XX.lm
plot(XX)
abline(XX.lm)
XX = as.data.frame(X);
XX$ym = substr(XX$'Last Updated',1,7)
XX$date = as.Date(X$`Last Updated`)
XX$dd   = as.integer(XX$date - min(XX$date))
XX$mm   = as.integer(XX$dd / 30 ) + 1
head(XX,2)
TMC0 = round((table(XX$Category) > 0),1)
dim(TMC0)
TMC = TMC0[1:52]
dim(TMC)
txTMC = lapply( 1:dim(TMC), FUN=function(k) colnames(TMC)[which(TMC[k,]>0)] )
arTMC = apriori( txTMC, parameter=list(support=0.3, confidence=0.6), control=list(verbose=FALSE) )
inspect(arTMC)
XXX = XX[,c("mm","Installs")]
library(data.table)
setDT(XX,key=c("mm"))
maxXX = XX[, .(maxInstalls=max(Installs)), by=mm]
plot(maxXX)
###
dim(X);   head(X,3)
plot(Rating ~ Installs, data = X)
XX = X[,c("Year","Installs")]
cor(XX)
X.lm = lm(Installs ~ Reviews, data = X)  #--> linear model lm() 即為線性回歸的模型 M()
X.lm
w = coef(X.lm);  w #拮据
# (Intercept)       speed  --> 表示線性回歸式為   y =     w0      +       w1 * u
#  -17.579095    3.932409                      dist = (-17.579095) + (3.932409) * speed
plot(Installs ~ Reviews, data = X)
abline(coef(X.lm))
u = X$Reviews;   mean(u)
y = X$Installs;    mean(y)
w1 = sum((u-mean(u))*(y-mean(y)))/sum((u-mean(u))^2) ;   w1   #-- = 5387.4/1370 = 3.932409
w0 = mean(y) - w1 * mean(u);   w0
X1 = data.frame(Reviews=c(100,1000,1e+07,2e+07))
##== 預測函式(predict())
X1$install = predict(X.lm, newdata=X1)
X1
dim(iris);   head(iris,2)
dim(X);
#=========R-tech6================
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data")
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
dim(X);
dim(X);
dim(iris);   head(iris,2)
dim(X,2);
dim(iris);   head(iris,2)
#   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
# 1          5.1         3.5          1.4         0.2  setosa
# 2          4.9         3.0          1.4         0.2  setosa
dim(X); head(X,2)
dim(iris);   head(iris,2)
dim(iris);   head(iris,2)
#   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
# 1          5.1         3.5          1.4         0.2  setosa
# 2          4.9         3.0          1.4         0.2  setosa
dim(X); head(X,2)
attach(iris)   ##== (1) 設定數據框為iris, 可以精簡以下的變量表示
attach(X)
##== 鳶尾花類別分布圖
plot.iris <- function(xx,yy,xxlab,yylab) {
plot(NULL,xlim=range(xx),ylim=range(yy),main="classified scatter plot of iris data",xlab=xxlab,ylab=yylab)
points(xx[Species=="setosa"],yy[Species=="setosa"],pch=1,col="blue")
points(xx[Species=="virginica"],yy[Species== "virginica"],pch=2,col="green")
points(xx[Species=="versicolor"],yy[Species== "versicolor"],pch=3,col="purple")
legend("topleft",legend=c("setosa","virginica","versicolor"), bty="n",col=c("blue","green","purple"),x.intersp=0.5, y.intersp=0.5,pch=c(1,2,3))
}
#=========R-tech6================
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data")
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
dim(iris);   head(iris,2)
#   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
# 1          5.1         3.5          1.4         0.2  setosa
# 2          4.9         3.0          1.4         0.2  setosa
dim(X); head(X,2)
attach(iris)   ##== (1) 設定數據框為iris, 可以精簡以下的變量表示
##== 鳶尾花類別分布圖
plot.iris <- function(xx,yy,xxlab,yylab) {
plot(NULL,xlim=range(xx),ylim=range(yy),main="classified scatter plot of iris data",xlab=xxlab,ylab=yylab)
points(xx[Species=="setosa"],yy[Species=="setosa"],pch=1,col="blue")
points(xx[Species=="virginica"],yy[Species== "virginica"],pch=2,col="green")
points(xx[Species=="versicolor"],yy[Species== "versicolor"],pch=3,col="purple")
legend("topleft",legend=c("setosa","virginica","versicolor"), bty="n",col=c("blue","green","purple"),x.intersp=0.5, y.intersp=0.5,pch=c(1,2,3))
}
plot.iris(Petal.Width, Petal.Length, "Petal.Width", "Petal.Length")
dim(X); head(X,2)
attach(X)   ##== (1) 設定數據框為iris, 可以精簡以下的變量表示
#=========R-tech6================
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data")
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
dim(X); head(X,2)
attach(X)   ##== (1) 設定數據框為iris, 可以精簡以下的變量表示
#   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
# 1          5.1         3.5          1.4         0.2  setosa
# 2          4.9         3.0          1.4         0.2  setosa
attach(iris)   ##== (1) 設定數據框為iris, 可以精簡以下的變量表示
plot.iris <- function(xx,yy,xxlab,yylab) {
plot(NULL,xlim=range(xx),ylim=range(yy),main="classified scatter plot of iris data",xlab=xxlab,ylab=yylab)
points(xx[Species=="setosa"],yy[Species=="setosa"],pch=1,col="blue")
points(xx[Species=="virginica"],yy[Species== "virginica"],pch=2,col="green")
points(xx[Species=="versicolor"],yy[Species== "versicolor"],pch=3,col="purple")
legend("topleft",legend=c("setosa","virginica","versicolor"), bty="n",col=c("blue","green","purple"),x.intersp=0.5, y.intersp=0.5,pch=c(1,2,3))
}
plot.iris(Petal.Width, Petal.Length, "Petal.Width", "Petal.Length")
dim(X); head(X,2)
dim(X); head(X,2)
plot.iris(Rating, Reviews, "Rating", "Reviews")
dim(X); head(X,2)
attach(X)   ##== (1) 設定數據框為X, 可以精簡以下的變量表示
plot.app <- function(xx,yy,xxlab,yylab) {
plot(NULL,xlim=range(xx),ylim=range(yy),
main="classified scatter plot of iris data",
xlab=xxlab,ylab=yylab)
points(xx[Species=="setosa"],yy[Species=="setosa"],
pch=1,col="blue")
points(xx[Species=="virginica"],yy[Species== "virginica"],
pch=2,col="green")
points(xx[Species=="versicolor"],yy[Species== "versicolor"],
pch=3,col="purple")
legend("topleft",
legend=c("setosa","virginica","versicolor"),
bty="n",
col=c("blue","green","purple"),
x.intersp=0.5,
y.intersp=0.5,
pch=c(1,2,3))
}
plot.app(Rating, Reviews, "Rating", "Reviews")
dim(X); head(X,2)
attach(X)   ##== (1) 設定數據框為X, 可以精簡以下的變量表示
plot.app <- function(xx,yy,xxlab,yylab) {
plot(NULL,xlim=range(xx),ylim=range(yy),
main="classified scatter plot of iris data",
xlab=xxlab,ylab=yylab)
points(xx[Type=="Free"],yy[Type=="Free"],pch=1,col="blue")
points(xx[Type=="Paid"],yy[Type== "Paid"],pch=2,col="red")
legend("topleft",
legend=c("setosa","virginica","versicolor"), bty="n",
col=c("blue","red"),
x.intersp=0.5, y.intersp=0.5,
pch=c(1,2))
}
plot.app(Rating, Reviews, "Rating", "Reviews")
legend("topleft",
legend=c("Free","Paid"), bty="n",
col=c("blue","red"),
x.intersp=0.5, y.intersp=0.5,
pch=c(1,2))
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
##== 模型的訓練階段: 由輸入數據(u)輸出數據(y) 求取模型 M = tree(y~u)
iris.tree = tree(Species ~ .,data=iris);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Species ~ .,data=iris);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
#   3) Petal.Length > 2.45 100 138.600 versicolor ( 0.00000 0.50000 0.50000 )
#     6) Petal.Width < 1.75 54  33.320 versicolor ( 0.00000 0.90741 0.09259 )
#      12) Petal.Length < 4.95 48   9.721 versicolor ( 0.00000 0.97917 0.02083 )
#        24) Sepal.Length < 5.15 5   5.004 versicolor ( 0.00000 0.80000 0.20000 ) * 葉結點 FR24
#        25) Sepal.Length > 5.15 43   0.000 versicolor ( 0.00000 1.00000 0.00000 ) * 葉結點 R25
#      13) Petal.Length > 4.95 6   7.638 virginica ( 0.00000 0.33333 0.66667 ) * 葉結點 FR13
#     7) Petal.Width > 1.75 46   9.635 virginica ( 0.00000 0.02174 0.97826 )
#      14) Petal.Length < 4.95 6   5.407 virginica ( 0.00000 0.16667 0.83333 ) * 葉結點 FR14
#      15) Petal.Length > 4.95 40   0.000 virginica ( 0.00000 0.00000 1.00000 ) * 葉結點 R15
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
iris.tree = tree(Type ~ .,data=iris);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
library(tree)
iris.tree = tree(Type ~ .,data=iris);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
#####===== (2C) iris例說明決策樹rpart操作程序 =====#####
library(rpart);   library(rpart.plot)
##== 訓練模型
iris.rpart = rpart(Species ~. , data=iris);   print(iris.rpart)
# 1) root 150 100 setosa (0.33333333 0.33333333 0.33333333)
#   2) Petal.Length< 2.45 50   0 setosa (1.00000000 0.00000000 0.00000000) *
#   3) Petal.Length>=2.45 100  50 versicolor (0.00000000 0.50000000 0.50000000)
#     6) Petal.Width< 1.75 54   5 versicolor (0.00000000 0.90740741 0.09259259) *
#     7) Petal.Width>=1.75 46   1 virginica (0.00000000 0.02173913 0.97826087) *
##== 繪出決策樹
rpart.plot(iris.rpart)
##== 預測值
Species.new.rpart3 = predict(iris.rpartA, newdata=iris);   Species.new.rpart3
Species.new.rpart = apply(Species.new.rpart3, 1, which.max)
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Species ~ .,data=iris);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
library(tree)
iris.tree = tree(Species ~ .,data=iris);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
iris.tree = tree(Type ~ .,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
#=========R-tech6================
setwd("/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data")
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
##== App 收費 type 分布圖
dim(X); head(X,2)
attach(X)   ##== (1) 設定數據框為X, 可以精簡以下的變量表示
plot.app <- function(xx,yy,xxlab,yylab) {
plot(NULL,xlim=range(xx),ylim=range(yy),
main="classified scatter plot of iris data",
xlab=xxlab,ylab=yylab)
points(xx[Type=="Free"],yy[Type=="Free"],pch=1,col="blue")
points(xx[Type=="Paid"],yy[Type== "Paid"],pch=2,col="red")
legend("topleft",
legend=c("Free","Paid"), bty="n",
col=c("blue","red"),
x.intersp=0.5, y.intersp=0.5,
pch=c(1,2))
}
plot.app(Rating, Reviews, "Rating", "Reviews")  #收費不一定比較好
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Type ~ .,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
iris.tree = tree(Type .,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
#                  Species
# Species.new.tree setosa versicolor virginica
#                1     50          0         0
#                2      0         47         1
#                3      0          3        49'
iris
iris.tree = tree(Species ~ .,data=iris);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
iris.tree = tree(Type ~ ,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
.
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Type ~ .,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=iris,level=0.95,interval="confidence")
plot.iris(Petal.Width, Petal.Length, "Petal.Width", "Petal.Length")
abline(h=2.45,col="purple");  segments(1.75,2.45,1.75,7,col="pink");  segments(0,4.95,1.75,4.95,col="red");
Species.new.tree = apply(Species.new.tree3, 1, which.max); Species.new.tree[41:60] #-- 將150*3的陣列 轉成 150*1 的向量
#####===== (2C) iris例說明決策樹rpart操作程序 =====#####
library(rpart);   library(rpart.plot)
log(e**2)
e = exp(10)
log(e)
log(e**2)
log(e**3)
nums <- c(10, 10**2, 10**3, 10**4, 10**5)
log10(nums)
plot.app(Rating, log10(Reviews), "Rating", "Reviews")  #收費不一定比較好
Reviews.log =log10(Reviews)
plot.app(Rating,Reviews.log, "Rating", "Reviews")  #收費不一定比較好
plot.app <- function(xx,yy,xxlab,yylab) {
plot(NULL,xlim=range(xx),ylim=range(yy),
main="classified scatter plot of iris data",
xlab=xxlab,ylab=yylab)
points(xx[Type=="Free"],yy[Type=="Free"],pch=1,col="blue")
points(xx[Type=="Paid"],yy[Type== "Paid"],pch=2,col="red")
legend("topleft",
legend=c("Free","Paid"), bty="n",
col=c("blue","red"),
x.intersp=0.5, y.intersp=0.5,
pch=c(1,2))
}
Reviews.log =log10(Reviews)
plot.app(Rating,Reviews.log, "Rating", "Reviews")  #收費不一定比較好
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Type ~ .,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
iris.tree = tree(Type ~ Type,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
iris.tree = tree(Type ~ Rating,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
iris.tree = tree(Rating ~ Type,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Rating ~ Type,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=iris,level=0.95,interval="confidence")
plot.iris(Petal.Width, Petal.Length, "Petal.Width", "Petal.Length")
abline(h=2.45,col="purple");
segments(1.75,2.45,1.75,7,col="pink");
segments(0,4.95,1.75,4.95,col="red");
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
iris.tree = tree(Rating ~ Reviews,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=iris,level=0.95,interval="confidence")
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=iris,level=0.95,interval="confidence")
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Rating ~ Reviews,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=iris,level=0.95,interval="confidence")
plot.iris(Petal.Width, Petal.Length, "Petal.Width", "Petal.Length")
Rating.log = log10(Rating)
Reviews.log =log10(Reviews)
Rating.log = log10(Rating)
plot.app(Rating.log,Reviews.log, "Rating", "Reviews")  #收費不一定比較好
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Rating ~ Reviews,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=iris,level=0.95,interval="confidence")
plot.iris(Petal.Width, Petal.Length, "Petal.Width", "Petal.Length")
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Rating ~ Reviews,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=X,level=0.95,interval="confidence")
plot.iris(Petal.Width, Petal.Length, "Petal.Width", "Petal.Length")
plot.app(Rating.log,Reviews.log, "Rating", "Reviews")
abline(h=2.45,col="purple");
segments(1.75,2.45,1.75,7,col="pink");
segments(0,4.95,1.75,4.95,col="red");
Species.new.tree = apply(Species.new.tree3, 1, which.max); Species.new.tree[41:60] #-- 將150*3的陣列 轉成 150*1 的向量
#-- 將150*3的陣列 轉成 150*1 的向量
# 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
#  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2
table( Species.new.tree, Species)
#                  Species
# Species.new.tree setosa versicolor virginica
#                1     50          0         0
#                2      0         47         1
#                3      0          3        49'
iris
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
iris.tree = tree(Rating ~ Reviews,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Reviews.log =log10(Reviews)
Rating.log = log10(Rating)
plot.app(Rating.log,Reviews.log, "Rating", "Reviews")  #收費不一定比較好
plot.app(Rating.log,Reviews, "Rating", "Reviews")  #收費不一定比較好
.log
plot.app(Rating.log,Reviews.log, "Rating", "Reviews")  #收費不一定比較好
plot.app(Rating,Reviews.log, "Rating", "Reviews")  #收費不一定比較好
#因變數   #自變數  #資料源
iris.tree = tree(Rating ~ Reviews,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
Species.new.tree3 = predict(iris.tree, newdata=X,level=0.95,interval="confidence")
plot.app(Rating.log,Reviews.log, "Rating", "Reviews")
abline(h=2.45,col="purple");
segments(1.75,2.45,1.75,7,col="pink");
segments(0,4.95,1.75,4.95,col="red");
#####=====*(2B) iris例說明決策樹tree操作程序及其中觀念 [殷,7.2, 7.9.2] =====#####
library(tree)
#因變數   #自變數  #資料源
iris.tree = tree(Rating ~ Reviews,data=X);    iris.tree   #-- * denotes terminal node(葉結點或終結點)
##== 繪製決策樹
plot(iris.tree);     text(iris.tree)  #-- 6個葉結點, 其餘均為決策結點, 數據分裂為二元劃分
