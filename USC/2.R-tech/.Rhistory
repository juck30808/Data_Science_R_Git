########## (P) 課前準備 ##########
##== (1) 本單元課程為數據擷取，有許多要從網絡上抓取數據，故請隨時保持網絡連線
##== (2) 從微信群組下載 本份講義程式檔 HUT02.R 放入本門課課程目錄，並以 RStudio開啟
##== (3) 若見到本編程檔為中文亂碼，請以 File-->Reopen with Encoding --> UTF8，則可看到中文碼顯示
##== (4) 修改本程式第4行，設定工作目錄為 本門課工作目錄
##== (5) 依本課程(1B)指示，下載本門課所需之軟件包至本機備用 -- 下行安裝指令只需執行一次
install.packages( c("RCurl","XML","rvest","xml2","curl","datesets","MASS","readxl","jsonlite") )
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "insurance.csv")
csv1 = read.csv("insurance.csv");       csv2 <- read.table("insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "/data/insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "data\insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "\data\insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "insurance.csv")
csv1 = read.csv("insurance.csv");       csv2 <- read.table("insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "insurance.csv")
csv1 = read.csv("insurance.csv");       csv2 <- read.table("insurance.csv")
csv1 = read.csv("insurance.csv");
csv2 <- read.table("insurance.csv")
#####===== (1C) 企業(檔案)數據 [黃文3.2] =====#####
##== (1)最常用的.csv檔案格式 (read.csv) [黃文3.2.1]
write.csv(Insurance, "insurance.csv")
csv1 = read.csv("insurance.csv");
csv2 <- read.table("insurance.csv")
##== (2).txt檔案格式兩種讀取方法的比較 (read.table(), read.csv()) [黃文3.2.1]
write.table(Insurance, "insurance.txt")
txt1 = read.csv("insurance.txt");       txt2 = read.table("insurance.txt")
write.table(Insurance, "insurance.comma",sep=",")
comma1 = read.csv("insurance.comma");
##== (1)..位置 [Data Taipei]
library(jsonlite)
download.file("https://tpairbox.blob.core.windows.net/blobfs/AirBoxData.gz","airbox.gz")
airbox = fromJSON(gzfile("airbox.gz"))              #-- 台北市空氣盒子開放數據
airbox.df = as.data.frame(airbox$entries);  dim(airbox.df);   head(airbox.df,2)   #-- 1198  9   #-- airbox.df <- as.data.frame(airbox[[2]])
download.file("https://tpairbox.blob.core.windows.net/blobfs/AirBoxData.gz","airbox.gz")
airbox = fromJSON(gzfile("airbox.gz"))              #-- 台北市空氣盒子開放數據
airbox.df = as.data.frame(airbox$entries);
airbox.df = as.data.frame(airbox$entries);
dim(airbox.df);
head(airbox.df,2)
##== (2)..UBIKE/GPS [Data Taipei]
download.file("http://data.taipei/youbike","ubike.gz")
ubike = fromJSON(gzfile("ubike.gz"))                #-- 台北市UBIKE開放數據 <-- 因其中有中文,在windows系統中無法解譯,在Mac可以
##== (2)..UBIKE/GPS [Data Taipei]
download.file("http://data.taipei/youbike","ubike.gz")
ubike = fromJSON(gzfile("ubike.gz"))                #-- 台北市UBIKE開放數據 <-- 因其中有中文,在windows系統中無法解譯,在Mac可以
#####===== (1E) 雲端(網絡)數據 [Munzert, Ch.13]-->(第3節)網絡爬虫 =====#####
library(RCurl)
download.file("http://www.wcc.nrcs.usda.gov/ftpref/data/climate/table/temperature/history/california/19l03s_tavg.txt",
"ftpfile1.txt")                   #-- 加州天氣數據 --  原為ftp 現為www
##== (2).FTP檔案列表 [Munzert, Ch.13]
library(RCurl)
ftplist = "http://www.wcc.nrcs.usda.gov/ftpref/data/climate/table/temperature/history/california/"
filelist = getURL(ftplist, dirlistonly = TRUE) #-- 加州天氣數據檔案列表
#FTP檔案列表
library(RCurl)
ftplist = "http://www.wcc.nrcs.usda.gov/ftpref/data/climate/table/temperature/history/california/"
filelist = getURL(ftplist, dirlistonly = TRUE) #-- 加州天氣數據檔案列表
##== (2D-3).網頁中表格格式 [http://rfunction.com/archives/1816]
url = "http://www.openintro.org/cont/donorProcess.php"
result = postForm(url, name="David Diez", email="david@openintro.org", phone="857-288-8547")
#網頁中格式
url = "http://www.openintro.org/cont/donorProcess.php"
result = postForm(url, name="David Diez", email="david@openintro.org", phone="857-288-8547")
##== (2D-4).網頁+參數 格式 [Munzert, Ch.16]
url = "http://www.amazon.com/s/ref=nb_sb_noss_2?url=node%3D2407749011&field-keywords=Apple"
firstSearchPage = getURL(url)
#####=====*(3D) 簡單HTML網頁頁面爬取 [殷3.5.2] =====#####
##== 數據爬取軟件包 RCurl
#    -- 用C語言庫的HTTP庫的R接口，提供處理HTTP協議通訊的相關功能
#    -- 核心函數getURL(): 主要處理GET請求，獲取其响應內容，並用到XPath語法(下一節)
##== 實驗2: 爬取R網站首 https://www.r-project.org/ 的更新信息
library(RCurl)
#response = getURL("https://www.r-project.org/")
response = getURL("http://www.weather.com.cn/weathern/101340101.shtml")
print(response)
##== 續實驗2:網頁解析 [殷3.5]
response.parser = htmlParse(response, asText=TRUE)
print(response.parser)
library(RCurl)  # 數據爬取軟件包 RCurl
response = getURL("http://www.weather.com.cn/weathern/101340101.shtml")
print(response)
##== 續實驗2:網頁解析 [殷3.5]
response.parser = htmlParse(response, asText=TRUE)
print(response.parser)
#####===== (4C) 提取網頁樹: xpathSApply [殷3.3] =====#####
##== xpathSApply(XML檔, XPATH): 以XPATH 抓取XML樹上的分支
##== 續實驗2:數據提取 [殷3.5]
xpathSApply(response.parser, "/html/body/div/div/div/div/div/ul/li[2]")
##== (3) 網絡爬虫 =====#####
library(RCurl)
#兩種寫法 download || ftplist.
download.file("http://www.wcc.nrcs.usda.gov/ftpref/data/climate/table/temperature/history/california/19l03s_tavg.txt","ftpfile1.txt")
ftplist = "http://www.wcc.nrcs.usda.gov/ftpref/data/climate/table/temperature/history/california/"
filelist = getURL(ftplist, dirlistonly = TRUE) #-- 加州天氣數據檔案列表
#網頁中格式
url = "http://www.openintro.org/cont/donorProcess.php"
result = postForm(url, name="David Diez", email="david@openintro.org", phone="857-288-8547")
url = "http://www.amazon.com/s/ref=nb_sb_noss_2?url=node%3D2407749011&field-keywords=Apple"
firstSearchPage = getURL(url)
parsedFirstSearchPage = htmlParse(firstSearchPage)  #-- 亞馬遜網站之行動電話數據-->現會要求權限,無法取得
#####=====*(3D) 簡單HTML網頁頁面爬取 [殷3.5.2] =====#####
library(RCurl)  # 數據爬取軟件包 RCurl
response = getURL("http://www.weather.com.cn/weathern/101340101.shtml")
print(response)
########## (4) 分析網頁信息 ##########
response.parser = htmlParse(response, asText=TRUE)
print(response.parser)
#####===== (Z0) 讀取數據 (ftpfile1.txt-->X) =====#####
X = readLines("ftpfile1.txt");   length(X);   X[1:10]  # [1] 1163
i = 1
BBi = strsplit(BB[i],split=" ")[[1]];   BBi
BBii = BBi[which(nchar(BBi)>-)]
#####===== (Z0) 讀取數據 (ftpfile1.txt-->X) =====#####
X = readLines("ftpfile1.txt");   length(X);   X[1:10]  # [1] 1163
#####===== (Z1) 抓出表格首行 (X-->indB) =====#####
indB = grep("day    oct",X);   length(indB);   indB   #-- 27  #-- 抓出字串的pattern
#####===== (Z2) 抓出第k表格 (k-->indB[k]-->BB) =====#####
k = 2;   indB[k]   #-- 49
BB = X[(indB[k]+2):(indB[k]+2+30)];   BB
#####===== (Z0) 讀取數據 (ftpfile1.txt-->X) =====#####
X = readLines("ftpfile1.txt");   length(X);   X[1:10]  # [1] 1163
i = 1
BBi = strsplit(BB[i],split=" ")[[1]];   BBi
BBii = BBi[which(nchar(BBi)>-)]
#####===== (Z0) 讀取數據 (ftpfile1.txt-->X) =====#####
X = readLines("ftpfile1.txt");   length(X);   X[1:10]  # [1] 1163
i = 1
BBi = strsplit(BB[i],split=" ")[[1]];   BBi
BBii = BBi[which(nchar(BBi)>0)]; BBii
BBiii = as.integer(BBii); BBii
TT = NULL
for(i in 1:31){
BBi = strsplit(BB[i],split=" "[[1]]); BBi
BBii = BBi[]
}
#####===== (5A) (KDD1数据取得) 網絡爬文 (URL->X) =====#####
library(RCurl)
URL = "http://www.weather.com.cn/weathern/101340101.shtml"
X = getURL(URL, .encoding="GB");  head(X)
#####===== (5B) (KDD2数据探索) 檢視網頁樹 (X->XX) =====#####
library(XML)
XX = xpathSApply(htmlParse(X), "//ul[@class='t clearfix']/li")  #-- 相對路徑 //...
length(XX);   XX[[1]]   #-- [1] 7
#####=====*(5C) (KDD3数据转换) 转为天气数据框 (X->XXX) =====#####
Xday = NULL;   Xweather = NULL;   Xtemp = NULL;   Xwind = NULL
for (k in 1:length(XX)) {
Xday[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/h1")[[k]] )
Xweather[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='wea']")[[k]] )
Xtemp[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='tem']")[[k]] )
Xwind[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='win']")[[k]] )
}
XXX = data.frame(day=Xday, weather=Xweather, temp=Xtemp, wind=Xwind);  dim(XXX);  head(XXX,3)  #-- [1] 7 4
#####=====*(3D) 簡單HTML網頁頁面爬取 [殷3.5.2] =====#####
library(RCurl)  # 數據爬取軟件包 RCurl
response = getURL("http://www.weather.com.cn/weathern/101340101.shtml")
print(response)
########## (4) 分析網頁信息 ##########
response.parser = htmlParse(response, asText=TRUE)
print(response.parser)
#####===== (4C) 提取網頁樹: xpathSApply [殷3.3] =====#####
##== xpathSApply(XML檔, XPATH): 以XPATH 抓取XML樹上的分支
##== 續實驗2:數據提取 [殷3.5]
xpathSApply(response.parser, "/html/body/div/div/div/div/div/ul/li[2]")
# [[1]] <li>  <a href="/logo/">Logo</a>  </li>
# [[2]] <li>  <a href="/foundation/board.html">Board</a>  </li>
# [[3]] <li>  <a href="http://cran.r-project.org/faqs.html">FAQs</a>  </li>
# [[4]] <li>  <a href="/other-projects.html">Related Projects</a>  </li>
xpathSApply(response.parser, "/html/body/div/div/div/div/div/h2")
# [[1]] <h2 id="download">Download</h2>
# [[2]] <h2 id="r-project">R Project</h2>
# [[3]] <h2 id="r-foundation">R Foundation</h2>
# [[4]] <h2 id="help-with-r">Help With R</h2>
# [[5]] <h2 id="documentation">Documentation</h2>
# [[6]] <h2 id="links">Links</h2>
xpathSApply(response.parser, "//div[@class='col-xs-6 col-sm-12']/h2")  ##-- 以相對路徑和識別碼來找比較快
#####===== (5A) (KDD1数据取得) 網絡爬文 (URL->X) =====#####
library(RCurl)
URL = "http://www.weather.com.cn/weathern/101340101.shtml"
#####===== (5A) (KDD1数据取得) 網絡爬文 (URL->X) =====#####
library(RCurl)
URL = "http://www.weather.com.cn/weathern/101340101.shtml"
X = getURL(URL, .encoding="GB");  head(X)
#####=====*(5C) (KDD3数据转换) 转为天气数据框 (X->XXX) =====#####
Xday = NULL;   Xweather = NULL;   Xtemp = NULL;   Xwind = NULL
for (k in 1:length(XX)) {
Xday[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/h1")[[k]] )
Xweather[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='wea']")[[k]] )
Xtemp[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='tem']")[[k]] )
Xwind[k] = xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='win']")[[k]] )
}
XXX = data.frame(day=Xday, weather=Xweather, temp=Xtemp, wind=Xwind);  dim(XXX);  head(XXX,3)  #-- [1] 7 4
#           day  weather          temp                     wind
# 1 24日（今天）     多云      \n13℃\n               \n\n\n\n\n
# 2 25日（明天） 小雨转晴 \n21℃/11℃\n        \n\n\n\n\n5-6级\n
# 3 26日（后天）       晴  \n19℃/9℃\n        \n\n\n\n\n4-5级\n
write.xlsx(XXX,"/Users/mcsl/Desktop/XXX.xlsx")  #-- 通常，爬到文後，解析後，趕快將標籤(tag)存檔
#####===== (5D) (KDD4数据模型) 这一周天气的简要显示 (table(XXX$..)) =====#####
table(XXX$weather)
# 多云       晴 小雨转晴
#    1        5        1
table(XXX$wind)   #-- 這數據不太乖，有沒有改進的方法？
# \n\n\n\n\n             \n\n\n\n\n\n        \n\n\n\n\n3-4级\n \n\n\n\n\n3-4级转4-5级\n        \n\n\n\n\n4-5级\n
#          1                        1                        1                        1                        2
# \n\n\n\n\n5-6级\n
#                 1
table(XXX$weather, XXX$wind)
#####===== (5E) (KDD5数据呈现) 天气数据图 (plot(XXX$..)) =====#####
par(family="STKaiti");
barplot(table(XXX$weather), main="本周天气分布图")
pie(table(XXX$weather), main="本周天气比例图")
levels(XXX$weather) = c("晴","多云","小雨转晴")
plot(XXX$day,as.integer(XXX$weather), main="本周天气时序图")
#####===== (5F) 几个进阶的处理 =====#####
k = 6
##== (1) 去除 \n ==###
xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='win']")[[k]] )
# [1] "\n\n\n\n\n5-6级\n"
library(stringr)
str_replace_all( xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='win']")[[k]] ), "\n","")
# [1] "5-6级"
##== (2) 提取最高气温与最低气温 ==###
A = str_extract_all( xmlValue( xpathSApply( htmlParse(X),"//ul[@class='t clearfix']/li/p[@class='tem']")[[k]] ),
"[:digit:]*")[[1]]
pander(paste0(">> (1) APP數據共: ",dim(X)[1],"筆紀錄\n\n"))
pander(paste0(">> (1) APP數據共: ",dim(X)[1],"筆紀錄\n\n"));
#####===== (1) (KDD1) 讀取數據(-->X) =====#####
library(readxl)
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
dim(X);
#####===== (1) (KDD1) 讀取數據(-->X) =====#####
library(readxl)
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
dim(X);
head(X,2)
#####===== (2) (KDD2-3) 數據轉換(X-->XX) =====#####
range(X$Rating)
table( cut(X$Rating, breaks=c(0,1,2,3,4,5)) )
range(X$Rating)
table( cut(X$Rating, breaks=c(0,1,2,3,4,5)) )
range(X$Rating)
aa = table( cut(X$Rating, breaks=c(0,1,2,3,4,5)) )
aa
aa[1]
aa[2]
range(X$Year)   #2010 - 2018
table(X$Year)
range(X$Year)   #2010 - 2018
table(X$Year)
XX = X[which(X$Year>=2018),];   dim(XX)
rownames(XX) = 1:dim(XX)[1]
#####===== (3) (KDD4) 數據模型(XX-->XX.group) =====#####
X.hc = hclust( dist( X[,c("Rating","Reviews","Installs")] ),method="ward.D")
X.group = cutree(X.hc, k=20)
X.group[1:50]
table(X.group)
## (KDD2) APP基本基料探索 (X)
```{r, echo=FALSE, warning=FALSE}
range(X$Rating)
range(X$Rating)
rating_cut = table( cut(X$Rating, breaks=c(0,1,2,3,4,5)) )
##--- Rtech04 關聯性分析 ----
```{r, echo=FALSE, warning=FALSE}
library(arules);library(igraph)
#####===== (1) (KDD1) 讀取數據(-->X) =====#####
library(readxl)
X <- as.data.frame(read_excel('/Users/juck30808/Documents/Github/USC_R_Git/2.R-tech/data/googleplaystore4_(7000).xlsX'))
dim(X);
head(X,2)
#####===== (2) (KDD2-3) 數據轉換(X-->XX) =====#####
range(X$Rating)
table( cut(X$Rating, breaks=c(0,1,2,3,4,5)) )
range(X$Year)   #2010 - 2018
table(X$Year)
XX = X[which(X$Year>=2018),];   dim(XX)
rownames(XX) = 1:dim(XX)[1]
#####===== (3) (KDD4) 數據模型(XX-->XX.group) =====#####
X.hc = hclust( dist( X[,c("Rating","Reviews","Installs")] ),method="ward.D"); X.hc
X.group = cutree(X.hc, k=20);X.group
Ncls = 20  #cause k =20
X[which(X.group==1),c("Rating","Reviews","Installs")]
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, max),0)
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, min),0)
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, mean),2)
round(apply(X[which(X.group==1),c("Rating","Reviews","Installs")], 2, sd),2)
X.group
#####===== (4) (KDD5) 數據解讀(XX.group) =====#####
kk = 1  #X.group(kk)
indKK = which(X.group==kk);   indKK
Gmean = NULL
for (kk in 1:Ncls) {
indKK = which(X.group==kk);
c(kk,length(indKK), apply(X[indKK,c("Rating","Reviews","Installs")], 2, mean))
Gmean = rbind(Gmean, c(kk,length(indKK), apply(X[indKK,c("Rating","Reviews","Installs")], 2, mean)))
}
##== Group Features (Gfeature) ==##
#colnames(Gmean)
round(Gmean[1,],2)
AA = paste0(round(Gmean[1,3:5],2), " * ", colnames(Gmean)[3:5]);  AA
BB = paste( AA, collapse=" + ");   BB
##==> 用迴圈包成Gfeature
Gfeature = NULL
for (k in 1:dim(Gmean)[1]) {
print(k)
AA = paste0(round(Gmean[k,3:5],2), " * ", colnames(Gmean)[3:5]);  AA
BB = paste( AA, collapse="+")
print(BB)
Gfeature[k] = BB
}
Gfeature
##==> 把Gmean,Gfeature合成數據框
Gm = as.data.frame(Gmean);  head(Gm)
colnames(Gm)[1:2] = c("ind","count");   head(Gm)
Gm$feature = Gfeature
head(Gm)
write.csv(Gm,"Team1.csv")
library(arules);library(igraph)
PD=table(X$Category,X$Year)
rownames(PD) = NULL;  #PD     # 1-33個品項  #PD[1:10,]
#以下計算只取PD值
txPD = lapply( 1:dim(PD)[1],
FUN=function(k) colnames(PD)[which(PD[k,]>0)] )
arPD = apriori( txPD[1:6],
parameter=list(support=0.06, confidence=0.8),
control=list(verbose=FALSE))
#lhs=>rhs 代表買左邊也會買右邊的意思，而支持度與信賴度，則分別代表了普遍性與信心水準。
inPD = inspect(arPD[9:20,])
#lhs=>rhs 代表買左邊也會買右邊的意思，而支持度與信賴度，則分別代表了普遍性與信心水準。
#inPD = inspect(arPD[9:20,])
graph.arPD = graph.edgelist( cbind(inspect(arPD)[1:50,]$lhs,
inspect(arPD)[1:50,]$rhs) )
library(arules);library(igraph)
PD=table(X$Category,X$Year)
rownames(PD) = NULL;  #PD     # 1-33個品項  #PD[1:10,]
txPD = lapply( 1:dim(PD)[1],
FUN=function(k) colnames(PD)[which(PD[k,]>0)] )
arPD = apriori( txPD[1:6],
parameter=list(support=0.06, confidence=0.8),
control=list(verbose=FALSE))
#@
# apriori演算法大概是這樣運作的，我們必須要設定support以及confidence:
pander(">> (1)我們採用 apriori 演算法\n\n");
pander(">> (2)支持度(support)：「規則」在資料內具有普遍性，也就是這些 A 跟 B 同時出現的機率多少\n\n");
pander(">> (3)信賴度(confidence)：「規則」要有一定的信心水準，也就是當購買 A 狀態下，也會購買 B 的條件機率\n\n")
kable(inspect(arPD[9:20,]))%>%
kable_styling(c("striped", "bordered")) %>%
kable_styling(full_width = F) %>%
column_spec(1, bold = T)
search()
arPD[3:31,]
